2025-06-22 21:31:51,765 - INFO - Building image: ghcr.io/all-hands-ai/runtime:oh_v0.39.1_rlz0fhk6tp8v8t9b_expzl0jyv1gathl0
2025-06-22 21:31:51,800 - INFO - [runtime c6b67718-1403-476b-aec4-5a7edf9e0a55-5b39f9adcb8b3366] Starting runtime with image: ghcr.io/all-hands-ai/runtime:oh_v0.39.1_rlz0fhk6tp8v8t9b_expzl0jyv1gathl0
2025-06-22 21:31:52,104 - ERROR - [runtime c6b67718-1403-476b-aec4-5a7edf9e0a55-5b39f9adcb8b3366] Error: Instance openhands-runtime-c6b67718-1403-476b-aec4-5a7edf9e0a55-5b39f9adcb8b3366 FAILED to start container!

2025-06-22 21:31:52,104 - ERROR - [runtime c6b67718-1403-476b-aec4-5a7edf9e0a55-5b39f9adcb8b3366] 500 Server Error for http+docker://localhost/v1.48/containers/ec651898fcf7bae186ca1f5b773cbc9d7c4319125c497753127f5d3bb35b7d0c/start: Internal Server Error ("Ports are not available: exposing port TCP 0.0.0.0:51071 -> 127.0.0.1:0: listen tcp 0.0.0.0:51071: bind: address already in use")
2025-06-22 21:31:52,151 - ERROR - ----------
Error in instance [23]: 500 Server Error for http+docker://localhost/v1.48/containers/ec651898fcf7bae186ca1f5b773cbc9d7c4319125c497753127f5d3bb35b7d0c/start: Internal Server Error ("Ports are not available: exposing port TCP 0.0.0.0:51071 -> 127.0.0.1:0: listen tcp 0.0.0.0:51071: bind: address already in use"). Stacktrace:
Traceback (most recent call last):
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/api/client.py", line 275, in _raise_for_status
    response.raise_for_status()
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http+docker://localhost/v1.48/containers/ec651898fcf7bae186ca1f5b773cbc9d7c4319125c497753127f5d3bb35b7d0c/start

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/hamza/OpenHands/evaluation/utils/shared.py", line 323, in _process_instance_wrapper
    result = process_instance_func(instance, metadata, use_mp, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/OpenHands/evaluation/benchmarks/readme_bench/run_infer.py", line 252, in process_instance
    call_async_from_sync(runtime.connect)
  File "/Users/hamza/OpenHands/openhands/utils/async_utils.py", line 54, in call_async_from_sync
    result = future.result()
             ^^^^^^^^^^^^^^^
  File "/Users/hamza/miniforge3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/miniforge3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/hamza/miniforge3/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/OpenHands/openhands/utils/async_utils.py", line 44, in run
    return asyncio.run(arun())
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/miniforge3/lib/python3.12/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/Users/hamza/miniforge3/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/miniforge3/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Users/hamza/OpenHands/openhands/utils/async_utils.py", line 37, in arun
    result = await coro
             ^^^^^^^^^^
  File "/Users/hamza/OpenHands/openhands/runtime/impl/docker/docker_runtime.py", line 158, in connect
    await call_sync_from_async(self.init_container)
  File "/Users/hamza/OpenHands/openhands/utils/async_utils.py", line 18, in call_sync_from_async
    result = await coro
             ^^^^^^^^^^
  File "/Users/hamza/miniforge3/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/OpenHands/openhands/utils/async_utils.py", line 17, in <lambda>
    coro = loop.run_in_executor(None, lambda: fn(*args, **kwargs))
                                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/OpenHands/openhands/runtime/impl/docker/docker_runtime.py", line 383, in init_container
    raise e
  File "/Users/hamza/OpenHands/openhands/runtime/impl/docker/docker_runtime.py", line 347, in init_container
    self.container = self.docker_client.containers.run(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/models/containers.py", line 883, in run
    container.start()
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/models/containers.py", line 420, in start
    return self.client.api.start(self.id, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/utils/decorators.py", line 19, in wrapped
    return f(self, resource_id, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/api/container.py", line 1136, in start
    self._raise_for_status(res)
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/api/client.py", line 277, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/hamza/Library/Caches/pypoetry/virtualenvs/openhands-ai-ATcgL5TR-py3.12/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 500 Server Error for http+docker://localhost/v1.48/containers/ec651898fcf7bae186ca1f5b773cbc9d7c4319125c497753127f5d3bb35b7d0c/start: Internal Server Error ("Ports are not available: exposing port TCP 0.0.0.0:51071 -> 127.0.0.1:0: listen tcp 0.0.0.0:51071: bind: address already in use")

----------[The above error occurred. Retrying... (attempt 1 of 1)]----------

2025-06-22 21:31:57,154 - INFO - Logging LLM completions for instance 23 to evaluation/evaluation_outputs/outputs/islamham__bugswarm_maven_lite2/CodeActAgent/meta.llama3-1-70b-instruct-v1_0_maxiter_20_N_llm.bedrock1-no-hint-numworker_10-1750651938-run_1/llm_completions/23
2025-06-22 21:31:57,186 - INFO - Building image: ghcr.io/all-hands-ai/runtime:oh_v0.39.1_rlz0fhk6tp8v8t9b_expzl0jyv1gathl0
2025-06-22 21:31:57,208 - INFO - [runtime 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Starting runtime with image: ghcr.io/all-hands-ai/runtime:oh_v0.39.1_rlz0fhk6tp8v8t9b_expzl0jyv1gathl0
2025-06-22 21:31:57,612 - INFO - [runtime 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Container started: openhands-runtime-10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d. VSCode URL: None
2025-06-22 21:31:57,612 - INFO - [runtime 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Waiting for client to become ready at http://localhost:39958...
2025-06-22 21:32:17,759 - INFO - [runtime 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Runtime is ready.
2025-06-22 21:32:19,044 - INFO - ------------------------------
2025-06-22 21:32:19,044 - INFO - BEGIN Runtime Initialization Fn
2025-06-22 21:32:19,045 - INFO - ------------------------------
2025-06-22 21:32:19,045 - INFO - **CmdRunAction (source=None, is_input=False)**
COMMAND:
git clone https://github.com/owlcs/owlapi.git
2025-06-22 21:32:28,235 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "0dc583e9b02a",
  "working_dir": "/workspace",
  "py_interpreter_path": "/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
Cloning into 'owlapi'...
remote: Enumerating objects: 215020, done.
remote: Counting objects: 100% (3399/3399), done.
remote: Compressing objects: 100% (1748/1748), done.
remote: Total 215020 (delta 3250), reused 1651 (delta 1651), pack-reused 211621 (from 4)
Receiving objects: 100% (215020/215020), 110.42 MiB | 22.50 MiB/s, done.
Resolving deltas: 100% (121520/121520), done.
[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
[Command finished with exit code 0]
--END AGENT OBSERVATION--
2025-06-22 21:32:28,236 - INFO - **CmdRunAction (source=None, is_input=False)**
COMMAND:
cd owlapi
2025-06-22 21:32:28,864 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "0dc583e9b02a",
  "working_dir": "/workspace/owlapi",
  "py_interpreter_path": "/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace/owlapi]
[Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
[Command finished with exit code 0]
--END AGENT OBSERVATION--
2025-06-22 21:32:28,865 - INFO - ------------------------------
2025-06-22 21:32:28,865 - INFO - END Runtime Initialization Fn
2025-06-22 21:32:28,866 - INFO - ------------------------------
2025-06-22 21:32:28,889 - INFO - [runtime 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Selected repo: None, loading microagents from /workspace/.openhands/microagents (inside runtime)
2025-06-22 21:32:28,893 - INFO - Loading user workspace microagents: []
2025-06-22 21:32:28,893 - WARNING - No search engine API key found, skipping search engine
2025-06-22 21:32:28,893 - INFO - Added microagent stdio server: fetch
2025-06-22 21:32:30,734 - INFO - [runtime 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Updated MCP config: []
2025-06-22 21:32:30,734 - INFO - Initializing MCP agent for url='http://localhost:39958/sse' api_key='******' with SSE connection...
2025-06-22 21:32:30,759 - INFO - Connected to server with tools: ['fetch']
2025-06-22 21:32:30,759 - INFO - Connected to MCP server url='http://localhost:39958/sse' api_key='******' via SSE
2025-06-22 21:32:30,759 - INFO - Disconnected from MCP server
2025-06-22 21:32:30,759 - INFO - Loaded 1 MCP tools: ['fetch']
2025-06-22 21:32:30,760 - INFO - Setting 1 MCP tools for agent CodeActAgent: ['fetch']
2025-06-22 21:32:30,760 - INFO - Tools updated for agent CodeActAgent, total 5: ['execute_bash', 'think', 'finish', 'str_replace_editor', 'fetch']
2025-06-22 21:32:30,760 - INFO - [Agent Controller 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] AgentController 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d - created new state. start_id: 0
2025-06-22 21:32:30,762 - INFO - [Agent Controller 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.RUNNING
2025-06-22 21:38:22,227 - WARNING - [Agent Controller 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Pending action active for 73.07s: CmdRunAction (id=17)
2025-06-22 21:38:22,227 - WARNING - [Agent Controller 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Pending action active for 73.07s: CmdRunAction (id=17)
2025-06-22 21:39:09,139 - INFO - [Agent Controller 10a1e143-6832-4de5-8aa7-e4e7003ac9d0-7f9dfafbe6379c9d] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.FINISHED
2025-06-22 21:39:09,461 - INFO - ------------------------------
2025-06-22 21:39:09,461 - INFO - BEGIN Runtime Completion Fn
2025-06-22 21:39:09,461 - INFO - ------------------------------
2025-06-22 21:39:09,461 - INFO - ------------------------------
2025-06-22 21:39:09,461 - INFO - END Runtime Completion Fn
2025-06-22 21:39:09,461 - INFO - ------------------------------
2025-06-22 21:39:09,462 - INFO - Got evaluation result for repo 23:
--------
{}
--------
2025-06-22 21:39:12,229 - INFO - Logging LLM completions for instance 29 to evaluation/evaluation_outputs/outputs/islamham__bugswarm_maven_lite2/CodeActAgent/meta.llama3-1-70b-instruct-v1_0_maxiter_20_N_llm.bedrock1-no-hint-numworker_10-1750651938-run_1/llm_completions/29
